{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d969362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62ee55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_uncertainty(method, tensor):\n",
    "    '''\n",
    "    Estimate classification uncertainty.\n",
    "    Arguments:\n",
    "    \n",
    "    method (str): name of method used to compute uncertainty\n",
    "    tensor (torch.tensor): output of classification network, dimension ( N(images), N(classes) )\n",
    "    Returns:\n",
    "    torch.tensor with dimension ( N(images) )\n",
    "    '''\n",
    "    tensor = torch.nn.functional.softmax(tensor, dim=1)\n",
    "    \n",
    "    if method == 'MarginSampling':\n",
    "        return margin_sampling(tensor)\n",
    "    elif method == 'Entropy':\n",
    "        return entropy(tensor)\n",
    "    elif method == 'VarRatio':\n",
    "        return var_ratio(tensor)\n",
    "\n",
    "def margin_sampling(tensor):\n",
    "    '''\n",
    "    Measure uncertainty as 1 - difference between probabilities of the two highest-ranking classes\n",
    "    '''\n",
    "    tensor_sorted = tensor.sort(dim=1, descending=True)[0] # sort class probabilities\n",
    "    return 1 - (tensor_sorted[:,0] - tensor_sorted[:,1])\n",
    "\n",
    "def entropy(tensor):\n",
    "    '''\n",
    "    Measure uncertainty as predictive entropy\n",
    "    '''\n",
    "    tensor_log = tensor.log()\n",
    "    return -(tensor*tensor_log).sum(dim=1)\n",
    "\n",
    "def var_ratio(tensor):\n",
    "    '''\n",
    "    Measure uncertainty as 1 - probability of highest-ranking class\n",
    "    '''\n",
    "    return 1 - tensor.max(dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3fd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_images(method, tensor, n_sel, **kwargs):\n",
    "    '''\n",
    "    Select set of unlabelled images to be added to training set\n",
    "    Arguments:\n",
    "    \n",
    "    method (str): name of method used to select images\n",
    "    tensor (torch.tensor): output of aggregate_uncertainty, dimension ( N(images) )\n",
    "    n_sel (int): number of images to select\n",
    "    Returns:\n",
    "    torch.tensor with index of selected images, dimension ( n_sel )\n",
    "    '''\n",
    "\n",
    "    if method == 'batch':\n",
    "        return batch_selection(tensor, n_sel, **kwargs)\n",
    "    elif method == 'maximum':\n",
    "        return maximum_selection(tensor, n_sel)\n",
    "    elif method == 'CoreSet':\n",
    "        return core_set(tensor, n_sel, **kwargs)\n",
    "\n",
    "def batch_selection(tensor, n_sel, **kwargs):\n",
    "    '''\n",
    "    Split randomly shuffled images in batches, compute aggregate score (sum) for each batch and select highest scores until n_sel is reached.\n",
    "    Necessary keyword argument:\n",
    "    batch_size (int): number of images per batch\n",
    "    '''\n",
    "    if (n_sel % kwargs['batch_size']) == 0:\n",
    "        batch_size_sel = int(n_sel / kwargs['batch_size'])\n",
    "    else:\n",
    "        batch_size_sel = (n_sel // kwargs['batch_size']) + 1\n",
    "    \n",
    "    r = torch.randperm(tensor.shape[0])\n",
    "    tensor_shuffle = tensor[r] # randomly shuffle images\n",
    "\n",
    "    batch_list = tensor_shuffle.split(kwargs['batch_size'])\n",
    "    batch_score_tensor = torch.tensor( [ b.sum().item() for b in batch_list ] )\n",
    "    batch_argmax = batch_score_tensor.sort(descending=True)[1][:batch_size_sel]\n",
    "\n",
    "    arg_sel = torch.concat( [r.split(kwargs['batch_size'])[ib] for ib in range(len(batch_list)) if ib in batch_argmax] )\n",
    "\n",
    "    return arg_sel\n",
    "\n",
    "def maximum_selection(tensor, n_sel):\n",
    "    '''\n",
    "    Select the n_sel images with the highest uncertainty.\n",
    "    '''\n",
    "    return tensor.sort(descending=True)[1][:n_sel]\n",
    "\n",
    "def core_set(tensor, n_sel, **kwargs):\n",
    "    '''\n",
    "    k-center greedy, limited to pool set and with distance weighted by uncertainty\n",
    "    '''\n",
    "    # compute matrix of distances between images\n",
    "    dist_mat = kwargs['embedding'] @ kwargs['embedding'].transpose(0, 1)\n",
    "    diag = dist_mat.diag().reshape( (kwargs['embedding'].shape[0], 1) )\n",
    "    dist_mat *= -2\n",
    "    dist_mat += diag\n",
    "    dist_mat += diag.transpose(0, 1)\n",
    "    dist_mat = torch.sqrt(dist_mat)\n",
    "\n",
    "    # choose first centroid randomly\n",
    "    centroids = torch.zeros(tensor.shape[0], dtype=torch.bool)\n",
    "    sel_idx = torch.randint( kwargs['embedding'].shape[0], (1,1) ).squeeze().item()\n",
    "    centroids[sel_idx] = True\n",
    "    \n",
    "    # select centroids (= data to be labelled) iteratively\n",
    "    for _ in range(n_sel-1):\n",
    "        d = dist_mat[~centroids][:,centroids] # remove centroids from row and keep only centroids for columns\n",
    "        unc = tensor[~centroids] # get uncertainty of images other than centroids\n",
    "        \n",
    "        mat_min = d.min(dim=1)[0] # get closest centroid for each image\n",
    "        weighted_mat_min = mat_min * unc # weight distance to closest centroid by uncertainty on image\n",
    "        sel_idx_ = weighted_mat_min.argmax().item() # select image with largest distance to closest centroid\n",
    "        sel_idx = torch.arange(tensor.shape[0])[~centroids][sel_idx_] # correct index for already selected images/rows\n",
    "        centroids[sel_idx] = True\n",
    "\n",
    "    return torch.arange(tensor.shape[0])[centroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d519ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a95fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, embedding=False):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        feat_vec = out.view(out.size(0), -1)\n",
    "        out = self.fc(feat_vec)\n",
    "        if embedding:\n",
    "            return out, feat_vec\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453576b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfcf512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train_model(model, train_loader):\n",
    "    total_step = len(train_loader)\n",
    "    curr_lr = learning_rate\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % 40 == 0:\n",
    "                if i == 10:\n",
    "                    print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f}\"\n",
    "                           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        # Decay learning rate\n",
    "        if (epoch+1) % 20 == 0:\n",
    "            curr_lr /= 3\n",
    "            update_lr(optimizer, curr_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "895804b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))\n",
    "        return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8b076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dd90997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs = 80\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Image preprocessing modules\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32),\n",
    "    transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cec6cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 dataset\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='data/',\n",
    "                                            train=False, \n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c15379ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_round = 10\n",
    "n_sel = 1000\n",
    "n_repeat = 3\n",
    "unc_method = 'Entropy'\n",
    "sel_method = 'CoreSet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2511a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "Accuracy of the model on the test images: 50.74 %\n",
      "\n",
      "Round 1\n",
      "Epoch [1/80], Step [11/20] Loss: 1.8890\n",
      "Epoch [41/80], Step [11/20] Loss: 0.5074\n",
      "Accuracy of the model on the test images: 58.45 %\n",
      "\n",
      "Round 2\n",
      "Epoch [1/80], Step [11/30] Loss: 1.7504\n",
      "Epoch [41/80], Step [11/30] Loss: 0.4887\n",
      "Accuracy of the model on the test images: 64.68 %\n",
      "\n",
      "Round 3\n",
      "Epoch [1/80], Step [11/40] Loss: 1.9879\n",
      "Epoch [41/80], Step [11/40] Loss: 0.3857\n",
      "Accuracy of the model on the test images: 69.53 %\n",
      "\n",
      "Round 4\n",
      "Epoch [1/80], Step [11/50] Loss: 1.9825\n",
      "Epoch [41/80], Step [11/50] Loss: 0.4475\n",
      "Accuracy of the model on the test images: 70.78 %\n",
      "\n",
      "Round 5\n",
      "Epoch [1/80], Step [11/60] Loss: 1.9512\n",
      "Epoch [41/80], Step [11/60] Loss: 0.4424\n",
      "Accuracy of the model on the test images: 72.44 %\n",
      "\n",
      "Round 6\n",
      "Epoch [1/80], Step [11/70] Loss: 1.9220\n",
      "Epoch [41/80], Step [11/70] Loss: 0.4319\n",
      "Accuracy of the model on the test images: 74.73 %\n",
      "\n",
      "Round 7\n",
      "Epoch [1/80], Step [11/80] Loss: 2.0349\n",
      "Epoch [41/80], Step [11/80] Loss: 0.3095\n",
      "Accuracy of the model on the test images: 76.27 %\n",
      "\n",
      "Round 8\n",
      "Epoch [1/80], Step [11/90] Loss: 1.9857\n",
      "Epoch [41/80], Step [11/90] Loss: 0.2738\n",
      "Accuracy of the model on the test images: 78.1 %\n",
      "\n",
      "Round 9\n",
      "Epoch [1/80], Step [11/100] Loss: 2.0985\n",
      "Epoch [41/80], Step [11/100] Loss: 0.2926\n",
      "Accuracy of the model on the test images: 78.04 %\n",
      "\n",
      "Round 0\n",
      "Accuracy of the model on the test images: 48.74 %\n",
      "\n",
      "Round 1\n",
      "Epoch [1/80], Step [11/20] Loss: 1.9520\n",
      "Epoch [41/80], Step [11/20] Loss: 0.5364\n",
      "Accuracy of the model on the test images: 59.7 %\n",
      "\n",
      "Round 2\n",
      "Epoch [1/80], Step [11/30] Loss: 2.0118\n",
      "Epoch [41/80], Step [11/30] Loss: 0.5099\n",
      "Accuracy of the model on the test images: 65.96 %\n",
      "\n",
      "Round 3\n",
      "Epoch [1/80], Step [11/40] Loss: 1.9629\n",
      "Epoch [41/80], Step [11/40] Loss: 0.6119\n",
      "Accuracy of the model on the test images: 68.87 %\n",
      "\n",
      "Round 4\n",
      "Epoch [1/80], Step [11/50] Loss: 2.0649\n",
      "Epoch [41/80], Step [11/50] Loss: 0.4093\n",
      "Accuracy of the model on the test images: 70.69 %\n",
      "\n",
      "Round 5\n",
      "Epoch [1/80], Step [11/60] Loss: 2.0748\n",
      "Epoch [41/80], Step [11/60] Loss: 0.4179\n",
      "Accuracy of the model on the test images: 72.87 %\n",
      "\n",
      "Round 6\n",
      "Epoch [1/80], Step [11/70] Loss: 2.0246\n",
      "Epoch [41/80], Step [11/70] Loss: 0.3702\n",
      "Accuracy of the model on the test images: 74.81 %\n",
      "\n",
      "Round 7\n",
      "Epoch [1/80], Step [11/80] Loss: 1.9984\n",
      "Epoch [41/80], Step [11/80] Loss: 0.3306\n",
      "Accuracy of the model on the test images: 76.3 %\n",
      "\n",
      "Round 8\n",
      "Epoch [1/80], Step [11/90] Loss: 2.0228\n",
      "Epoch [41/80], Step [11/90] Loss: 0.2417\n",
      "Accuracy of the model on the test images: 77.2 %\n",
      "\n",
      "Round 9\n",
      "Epoch [1/80], Step [11/100] Loss: 2.0811\n",
      "Epoch [41/80], Step [11/100] Loss: 0.3133\n",
      "Accuracy of the model on the test images: 78.55 %\n",
      "\n",
      "Round 0\n",
      "Accuracy of the model on the test images: 49.84 %\n",
      "\n",
      "Round 1\n",
      "Epoch [1/80], Step [11/20] Loss: 1.8716\n",
      "Epoch [41/80], Step [11/20] Loss: 0.3985\n",
      "Accuracy of the model on the test images: 59.46 %\n",
      "\n",
      "Round 2\n",
      "Epoch [1/80], Step [11/30] Loss: 1.8788\n",
      "Epoch [41/80], Step [11/30] Loss: 0.5609\n",
      "Accuracy of the model on the test images: 63.56 %\n",
      "\n",
      "Round 3\n",
      "Epoch [1/80], Step [11/40] Loss: 1.9248\n",
      "Epoch [41/80], Step [11/40] Loss: 0.3545\n",
      "Accuracy of the model on the test images: 68.79 %\n",
      "\n",
      "Round 4\n",
      "Epoch [1/80], Step [11/50] Loss: 1.9112\n",
      "Epoch [41/80], Step [11/50] Loss: 0.3633\n",
      "Accuracy of the model on the test images: 72.03 %\n",
      "\n",
      "Round 5\n",
      "Epoch [1/80], Step [11/60] Loss: 2.0799\n",
      "Epoch [41/80], Step [11/60] Loss: 0.2970\n",
      "Accuracy of the model on the test images: 73.65 %\n",
      "\n",
      "Round 6\n",
      "Epoch [1/80], Step [11/70] Loss: 2.1026\n",
      "Epoch [41/80], Step [11/70] Loss: 0.4167\n",
      "Accuracy of the model on the test images: 75.03 %\n",
      "\n",
      "Round 7\n",
      "Epoch [1/80], Step [11/80] Loss: 1.9626\n",
      "Epoch [41/80], Step [11/80] Loss: 0.2525\n",
      "Accuracy of the model on the test images: 77.21 %\n",
      "\n",
      "Round 8\n",
      "Epoch [1/80], Step [11/90] Loss: 2.1069\n",
      "Epoch [41/80], Step [11/90] Loss: 0.2927\n",
      "Accuracy of the model on the test images: 77.17 %\n",
      "\n",
      "Round 9\n",
      "Epoch [1/80], Step [11/100] Loss: 2.1844\n",
      "Epoch [41/80], Step [11/100] Loss: 0.3626\n",
      "Accuracy of the model on the test images: 78.02 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for irepeat in range(n_repeat):\n",
    "\n",
    "    train, pool = torch.utils.data.random_split(train_dataset, [1000, len(train_dataset)-1000])\n",
    "    #pool, _ = torch.utils.data.random_split(pool, [int(len(pool)/2), int(len(pool)/2)]) # ugly hack to reduce memory for Core-set\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train,\n",
    "                                               batch_size=100, \n",
    "                                               shuffle=True)\n",
    "    pool_loader = torch.utils.data.DataLoader(dataset=pool,\n",
    "                                               batch_size=100, \n",
    "                                               shuffle=False)\n",
    "    accuracy_list = []\n",
    "\n",
    "    for ir in range(n_round):\n",
    "        print(f'Round {ir}')\n",
    "        # create model\n",
    "        model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # train\n",
    "        train_model(model, train_loader)\n",
    "\n",
    "        # test\n",
    "        accuracy_list.append( test_model(model, test_loader) )\n",
    "\n",
    "        if sel_method == 'random':\n",
    "            sel_idx = torch.randint(len(pool), (n_sel,))\n",
    "        else:\n",
    "            # inference on pool set\n",
    "            uncertainty = []\n",
    "            embedding = []\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, labels in pool_loader:\n",
    "                    images = images.to(device)\n",
    "                    if sel_method == 'CoreSet':\n",
    "                        outputs, embed = model(images, embedding=True)\n",
    "                        embedding.append(embed)\n",
    "                    else:\n",
    "                        outputs = model(images)\n",
    "                    unc = estimate_uncertainty(unc_method, outputs)\n",
    "                    uncertainty.append(unc)\n",
    "            uncertainty = torch.cat(uncertainty)\n",
    "            \n",
    "            if sel_method == 'CoreSet':\n",
    "                embedding = torch.cat(embedding)\n",
    "                lin_mat = torch.ones([embedding.shape[1], 4], device=f'cuda:{torch.cuda.current_device()}')\n",
    "                embedding = embedding @ lin_mat\n",
    "                del lin_mat\n",
    "\n",
    "            # select images to label from pool and add to training set\n",
    "            sel_idx = select_images(sel_method, uncertainty, n_sel, batch_size=10, embedding=embedding)\n",
    "        selected = torch.utils.data.Subset(pool, sel_idx)\n",
    "        train = torch.utils.data.ConcatDataset([train, selected])\n",
    "\n",
    "        # keep only non-selected images in pool\n",
    "        mask = torch.ones(len(pool), dtype=torch.bool)\n",
    "        mask[sel_idx] = False\n",
    "        not_sel_idx = torch.arange(mask.shape[0])[mask]\n",
    "        pool = torch.utils.data.Subset(pool, not_sel_idx)\n",
    "\n",
    "        # make new loaders\n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train,\n",
    "                                                   batch_size=100, \n",
    "                                                   shuffle=True)\n",
    "        pool_loader = torch.utils.data.DataLoader(dataset=pool,\n",
    "                                                   batch_size=100, \n",
    "                                                   shuffle=False)\n",
    "        torch.cuda.empty_cache()\n",
    "        print('')\n",
    "\n",
    "    if sel_method == 'random':\n",
    "        with open(f'output/random_{irepeat}.json', 'w') as f:\n",
    "            json.dump(accuracy_list, f)\n",
    "    else:\n",
    "        with open(f'output/{unc_method}_{sel_method}_{irepeat}.json', 'w') as f:\n",
    "            json.dump(accuracy_list, f)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d3ac59ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f74c0e7fa50>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAb9UlEQVR4nO2de3Cc1Znmn1fdrbtkSb4b28gGw5AQYohhSGJYIAmVUMwSKgkTUpXlDyae3R2qJrWzW0tlqzbZqt2qma1NUtk/NrPOhArZyoZwyUzYbBJuy8AkMxiDA7axwVx8wbIsy5al1qV1aendP7pdMdR5juRWq2XnPL8ql1vn6dPfq6/77U99nn7fY+4OIcTvP3WLHYAQojYo2YVIBCW7EImgZBciEZTsQiSCkl2IRMjOZ7KZfRrAdwBkAPyNu//lLPeXzyfEAuPuFhq3Sn12M8sAOADgUwCOAtgJ4G533xeZo2QXYoFhyT6fP+OvA/CWu7/j7pMAHgJwxzweTwixgMwn2S8C8O5ZPx8tjwkhzkPm9Zl9LpjZNgDbFvo4Qog480n2HgDrzvp5bXnsPbj7dgDbAX1mF2Ixmc+f8TsBbDKzDWZWD+CLAB6vTlhCiGpT8ZXd3Ytmdh+AJ1Cy3h5w99eqFtkc+Pq//3dUW7VmNdXWr+dLCw0NOar1nxwIjvf1n6ZzCiN5qvUdP0q1A2++RbWjPb1UO3biZHB8rDBO5xiCi7cAgEyGv0RmZqiEGRCxQvfnfKnONOPnqtpU8juPj/PneV6f2d39FwB+MZ/HEELUBn2DTohEULILkQhKdiESQckuRCIo2YVIhAX/Bt1C8sILL3AxYpFctukSqt36qZuo9sl/tjU4vmzFch5HYwuVJscKVDvdf5xqRw6+Q7V/+sdfB8effvYf6Jxdew/wOAaHqFaX4Tal14W1zMwUn+MRLy/yfFbblovZa7FjVWrLscesNA6GruxCJIKSXYhEULILkQhKdiESQckuRCJU3JaqooNVucS1++JuqsUKOCy6ojpNtS0fviI4ftcdn6ZzrrzqKqqt7d5ItcYmvoqPcNchAMDU2Ghw/OiRI3TOzh3c1fi/Tz5JtWdf2EW1E6fDcWSzGToHkdX486QO5rxnfHwc09PTVW9LJYS4gFCyC5EISnYhEkHJLkQiKNmFSAQluxCJcEFbb/WNTVTLRqy3zs4uqrW3tVPt9Km+4PjKTm6T3XbTtVT7w2s3U+2jW2+kWlNbB9Uy2dbgeM6KfE4xbJMBwPG+Y1R7/JfPUO1//uCh4Pi+w7zAJ5ttoFq1vbeFKGg5H44n600IoWQXIhWU7EIkgpJdiERQsguRCEp2IRJhXtabmR0CMAxgGkDR3bfMcv+q+idNTY1Ui7Uzy2T4e1xDUzPVOjuXBseH84N0zopO/njLOrhld8NHP0K1u27/JNVWrVwZHM828jgQsSkR6Rk3nufbXu367d7g+N/8hG8H+Pc79lBtgocBM/58uoctx+jLPqZV/BLm9lqtrLdqNJy82d3DG4wJIc4b9Ge8EIkw32R3AE+a2ctmtq0aAQkhFob5/hm/1d17zGwFgKfM7HV3f/7sO5TfBPRGIMQiM68ru7v3lP8/AeBvAVwXuM92d98y2+KdEGJhqTjZzazFzNrO3AZwK4DwEqwQYtGp2Hozs40oXc2B0seB/+3u/2WWOVW13pojNlnMzMjV808vkV6OVIxV0Q1H7KmOjiVUGxocoNqdn/hDqt37pX8eHF+zahWdk2ngFmamnmuYGufS2Ehw/GgvN24efPRXVHvkl3z7qrGILVdnYQ92ZoY3FoVHroHRl3DUs4toZEbEkmNKYSGsN3d/B8CHK50vhKgtst6ESAQluxCJoGQXIhGU7EIkgpJdiESoRiHM4hGxJmaI5QIAUzO8+WIuU0+1YjHs8QwNDdE5ML63WbHIY5yc5u/DjzzxG6qNTIYtpT/5At+Pbt2a5VTL1POmng05/vKZJi5UV2e4ISYA3PNZXs2Xy/Hn+uFf8fNRGA/HmM3y18BUkWs+w5/PqGsLbvVVYn87qfSLPZKu7EIkgpJdiERQsguRCEp2IRJByS5EIlzQq/HufIWzLrIs2dzAtxkqjEebnQWH2Sp9aQpfvfXJSaplI07D8ASV8POnwyvTU5FjfeXu26m2bkUH1aaz3LmoI5qBOxCtLTmqff5TW6mWy/B5P3t2Z3B8oshfIBNFfoLHC/w8FokTAgAeXScnc2JbRvEDUXRlFyIRlOxCJIKSXYhEULILkQhKdiESQckuRCJc0NZbUzMvqvjgZVdQbeP6dVQbLoxR7YUXdwTH8yPDdE42y99Pi1PcxslFtqiyyN5W0zNhU+apf+JbKzU38z5z/+KOW6i2rLODaplM+HeLnQ/PcpuytYnbfLfdyBsXF4iN9sRzu+icugZ+rEwdj39kZpRqpC0cgAoLYajtzB9LV3YhEkHJLkQiKNmFSAQluxCJoGQXIhGU7EIkwqzWm5k9AOB2ACfc/cryWBeAnwDoBnAIwF3uzvc5WiDWrruUah1rNlJtPFKJtvWGa/ljdnUExx957BE6JxexccbH+fZJqIt0NItU+xVJ7zqb5nOe3fEq1VqbeQ+6z936Map1toTtvKkMP/eZOq4hx69LuQau3XJdeNOiE/2n6Jzndr5OtWmP9KAjfeFKGrdL63Phqr3o9k9EmpriFZhzubL/AMD7uxXeD+AZd98E4Jnyz0KI85hZk7283/r7dxm8A8CD5dsPAvhsdcMSQlSbSj+zr3T33vLt4wBWVikeIcQCMe+vy7q7x7ZiNrNtALbN9zhCiPlR6ZW9z8xWA0D5/xPsju6+3d23uDv/ArMQYsGpNNkfB3BP+fY9AH5WnXCEEAvFXKy3HwO4CcAyMzsK4OsA/hLAw2Z2L4DDAO5ayCAZ7a280eDu3buptnLFaqrF7I5lXeEqu49+5Go658A7h6g2NsNPf3NzM9VmIttXNWbD5yQXsa6mJvnj/fL//SPVWup5/H/0ibAt19IUsdcizSjrI1tNtbXyc1VfF573x7fdTOeMjHGbcufed6jW0MhtyvZm3uR0WVdncHxwlDe+LBTCFXYjo7xqc9Zkd/e7ifSJ2eYKIc4f9A06IRJByS5EIijZhUgEJbsQiaBkFyIRrJJmdxUfLPJNu0ro6Gyj2vQkt3GyGW5CzGS5RbJ2zdrgeHsrt5MOHXqbxxGpktq04WKqrV/HG2Zefumm4HhDQ8R4iVh5I2O8ieLgQD/V1i4NPzcrly+hc9rauDYTeeUMj/AYe3vD3/fqH+JzjhznBZw79/CKuMkif801RWzKiclwpVp+jFtvPhM+1sjICIrFYtA/1pVdiERQsguRCEp2IRJByS5EIijZhUgEJbsQiXBBW2/ZSGXY9BRv5lgfaWxYl+GVdPXEPpmc5BZJa8ROGs3zPeIykQaFa1bzqr0/2Lg+OP7Jm26gc27eej3VVi7voNrxY0eptnPnS8HxQ8d6g+NAvNLPnF+Xxid5ldqhI4eD42++fYTOeesYt97yhYgdFtmDLxOxe1lv0azx32uanA9Zb0IIJbsQqaBkFyIRlOxCJIKSXYhEuKBX46+49v0b1fyOwhhf6R7N89XWqcIQ1SbG8sHxbGTlvKmJ9yUrRrZkGh4tUG1qOtKrrS58iruWtNA5V1y6gWofv3Yz1T50OZ/X0RF2ISYmuUtyrOcY1QZODVLNZ3jfwDrioGRJbzoAGBnjMR7q7aPagYN8hf9ID23AjOHxSaJEfi/SK3F4OK/VeCFSR8kuRCIo2YVIBCW7EImgZBciEZTsQiTCrNabmT0A4HYAJ9z9yvLYNwB8BcCZJmRfc/dfzHqwKltvm6+/hWrTdbyX3BTp3wUAmUghDKbDBTRDp3lxx9BJXiwyM8H7oM1M8YILWjkBYIbZNbHnOXI+cjleNLR8aXjbIgC45srLguOXdfMintUrllKttaGeavkhbpcOj4VtrZFxbq9NRQprOjvaK9JGIn3ydu55Izi+az/fampgYDB8nLECitPTFVtvPwAQMrS/7e6by/9mTXQhxOIya7K7+/MABmoQixBiAZnPZ/b7zGy3mT1gZvzvOSHEeUGlyf5dAJcA2AygF8A32R3NbJuZvWRm4W4GQoiaUFGyu3ufu097qTXH9wBcF7nvdnff4u5bKg1SCDF/Kkp2Mzt7SfVOAHurE44QYqGYi/X2YwA3AVgGoA/A18s/bwbgAA4B+FN35/7T7x6rqtbbTbfcTLX8yBjVJiPWSjHS68xJpZRF7LrJab610vgIr8wbOnmcalNjfL3ULGyVZbPcuspENLbNEABMToW3LQKAjZdeGhy/fuvH6JzWHLcUl7bwKrVlbdxmLeTDttzYGK8qrIv0ixvKcwstVtHX1carDletXBkcn4pURe49cDA4/tMnnkf/wGDwREY2ACvh7ncHhr8/2zwhxPmFvkEnRCIo2YVIBCW7EImgZBciEZTsQiTCrKvx5zPXfuQaqo2Ocuvt5MlTVDt9OrL1D7HKhguDdI5H7JjmRr7d0dotn6Da23t3UA3T4d+7LbINVcx9HZ/g8TdEtr063tMTHN93gFdy3X7n56m2pLWVam+/+jLVLl62Nji+tJlbaAcO7KdafY7blGtX8Yq+wgQ/V/vefDs43hhpVnr1By8Pjv/q+RfpHF3ZhUgEJbsQiaBkFyIRlOxCJIKSXYhEULILkQgX9F5vX/jC56i2atUqqtXXc/tkxnnl1TixT06d5lVoJ0/wPb4GIo0SV2y4gWqZGW6HzYweDo4XCrzK6/TpQf54M/wpGxvlVXv54fDvdnqIW6Ldl4Qr5QDgrru/RLUN3Rup1tjaERy/8hJukw0cDjeABICnn3qaagffDFeiAcDS5eE4AGDF8rAFWxjhzxlrsvnYk7/BiYEh7fUmRMoo2YVIBCW7EImgZBciEZTsQiTCBb0av3Qp3y6opYX3/Ors5G3uly1bRrW169cFx1dGVv6zpG8dAJwa4Cv1/SO8v1tTjj/mYN+7wfF9+1+nc4byeaq1NrdRrW0J1woT4ZXk/AA/1likeGn5qnCfNgC491/eR7Utt4Ydm0wTf31c3sV7CjYXeYz7X3uNas8+8yuqvb5vd3B8MtIn75Lui4LjP/y7J3C8f0Cr8UKkjJJdiERQsguRCEp2IRJByS5EIijZhUiEuWz/tA7ADwGsRGm7p+3u/h0z6wLwEwDdKG0BdZe78wZuqL71tmRJrK8aP9RMZEujGE2kJ1jX0i46p7t7PdUuvTTcRwwAJsZ5j7S/f+Y5qvX0hnu/xXqgNbfwXni5yNZQ7e3tVFu1OmyVnerjdmN+mP/OxchWSNORp/NLX/nz4Pi//jdfpXOOnOD2Wgt4HDdvDve7A4DpqUmqvbE7bNk99ywvunn9tV3B8Yf+zxPoO1m59VYE8Bfu/gEA1wP4MzP7AID7ATzj7psAPFP+WQhxnjJrsrt7r7vvKt8eBrAfwEUA7gDwYPluDwL47ALFKISoAuf0md3MugFcDWAHgJVn7dx6HKU/84UQ5ylz7htvZq0AHgPwVXfPm/3uY4G7O/s8bmbbAGybb6BCiPkxpyu7meVQSvQfuftPy8N9Zra6rK8GEFx5cfft7r7F3bdUI2AhRGXMmuxWuoR/H8B+d//WWdLjAO4p374HwM+qH54QolrMxXrbCuAfAOwBcMbk+BpKn9sfBrAewGGUrDfejA3Vt966urjlVan1FptXSYVgJsPfT5ubeeVVLtNAtRP9fVSbKoYtnq5YhWA7tzBjPejGR7lV1t4W/t2WLu2gc470HOdxRHoDTkZsSss2Bsf/ZBuvlLvlc1+m2uFDx6h201XcelvT1UG1xobwa2S8wC3AvqPhXoN3/PGXsOe1fcGTNetndnf/NQB2pvmGZEKI8wp9g06IRFCyC5EISnYhEkHJLkQiKNmFSIQ5f4PufCS2jVOMmPVWLBbPeV7c5uNxFCLWykQdr5KaMR5jS2vY8lq1ittCK1avoVphjNtafX3hCjsAGCRbYi3paKVz1pBKOQA4eIQfq6GRN74cHws37vwf//07dE42F7brAOBjN3ID6pU3TlItv5w/15etD1ufFolj1cWbguO5Bj5HV3YhEkHJLkQiKNmFSAQluxCJoGQXIhGU7EIkwgVtvVVKXR1/j8tm+SmppOotNieTyVCtWOR7vXnEzusk1W3ruzfQOd3dG6nW3MSr73a+9CLVJibD8R/v5Q0nL7/8Mqp1dfE9+E4ODFGtsSUcf0Mjrzh89NGf82Plue1522c+Q7V1a1dQLdMYfh2MTfDXwNjISHC8WOQNMXVlFyIRlOxCJIKSXYhEULILkQhKdiES4YJejZ+JbAkUW3GPFcLMRFbPz26fPZfx2eKIMUlWswEgk+FP2/IVq8JzIi7DyVO8gKOpga/GX76Jb1+Vz+eD4wcPvk3n9B7j/d3Wb7ySaqjnPfn6j70VHG9p5z35pqZ5EdJTT/2SagOneA+9tz5yFdVAXnKHDx+kU04OhVfje3r5udCVXYhEULILkQhKdiESQckuRCIo2YVIBCW7EIkwq/VmZusA/BClLZkdwHZ3/46ZfQPAVwD0l+/6NXf/xUIFGiKXy1GtMD7OJ8YKWiI2WiXWW0yLWYDTEVuxsZH3GWtp7wiOD4/yHmjvHDxENYtU3axby3vX5bLh60j7Et6DLratVa6V96err+evg9/tWPZeTvWFt08CgMZmHiPqePHSb57j8f9292+plm3sCAuRcz8yGD7WMCmQAebmsxcB/IW77zKzNgAvm9lTZe3b7v7f5vAYQohFZi57vfUC6C3fHjaz/QAuWujAhBDV5Zw+s5tZN4CrUdrBFQDuM7PdZvaAmXVWOzghRPWYc7KbWSuAxwB81d3zAL4L4BIAm1G68n+TzNtmZi+Z2UvzD1cIUSlzSnYzy6GU6D9y958CgLv3ufu0u88A+B6A60Jz3X27u29x9y3VCloIce7MmuxWWk7+PoD97v6ts8ZXn3W3OwHsrX54QohqMZfV+I8D+DKAPWb2SnnsawDuNrPNKNlxhwD86QLEF+WDH+KVUEND4aorADjZ30+1kYh1MTkZroaK9ZmLVb3F5sWst5YWbg21LekIjh8+9C6dwyrUACCX4/H39PZSbT2x5SaLvKJsJPKcvXvwANWa2/j2Tyx6n57gj9fAH296mvegK05xrTDAbTkUw9VykRaFWNIWfg2cNP6amstq/K8BhMzimnrqQoj5oW/QCZEISnYhEkHJLkQiKNmFSAQluxCJcEE3nMzW11Nt9UW8Imv5Sr4VT2FklGoDp08HxwfJOBC38sZjlXkR6iNNIMcK4ccsRqy8hsYmqjW38Aq7+iw//0cOHyXH4hVqjU3cUswPnqKaT/JrVsbC/lUhZm028a2h2klVIQCcOj1AtYnItkwjI4PB8VwLf15shpzHmA1MFSHE7xVKdiESQckuRCIo2YVIBCW7EImgZBciES5o623PXl5Vu7Sri2qdnbypTnMztzs2dHYEx4vFdXROPlLJNXCK20nvvsur1GINEevrw/GT/o8lrbmZag0N3HqbiTREbCDnsaurnc7pj+w5h0j1oEWaQNbXhxt+Fgr8UPlh/pxddsWHqLZiLe/WdqKPV70NNoRttPwot22P94X3xSsW+R6BurILkQhKdiESQckuRCIo2YVIBCW7EImgZBciES5o6+3YEW5P9feGm/gBQEsrr2rqrMCya23lVlhTZF+29eu4ZRerlpsu8saGIA0Rl0QqqLyOvwwmp7iVs3Q5339toC98/o8e5k0qG+r5uYqRzfBrVvuSsNU3kueViv0nTlDtyGG+R9w11/Ju6W++wRtm+kz4HK9atozOGW8Jv4ZHI68bXdmFSAQluxCJoGQXIhGU7EIkgpJdiESYdTXezBoBPA+goXz/R93962a2AcBDAJYCeBnAl92d7+2zAGQzPPyZSI+x/CAvdMjnh6nW2xMuPmiNbD/UHtGWtPOikEJhjGqZBl64wlb/vSlS0EL6tAHAlR/aTDXP8jgmx8KVJkuXcOfi8LuHqBbZ1Si6Ap0hK/WZDO+FV5zkr52jR/hq/Oarr6Xa0q7VVNv18q+D46tX8l/6ho/fHBw/1sNdqLlc2ScA3OLuH0Zpe+ZPm9n1AP4KwLfd/VIApwHcO4fHEkIsErMmu5c489aZK/9zALcAeLQ8/iCAzy5EgEKI6jDX/dkz5R1cTwB4CsDbAAbd/cw3OI4C4MW8QohFZ07J7u7T7r4ZwFoA1wH4g7kewMy2mdlLZvZSZSEKIarBOa3Gu/sggGcBfBRAh5mdWSFbC6CHzNnu7lvcnX+XUAix4Mya7Ga23Mw6yrebAHwKwH6Ukv7z5bvdA+BnCxSjEKIKzKUQZjWAB80sg9Kbw8Pu/nMz2wfgITP7zwB+C+D7CxhnEI9sdQOEe48BQF0d1yLTUCQFKCf7++mcUyd5X7XGRr6NEzsWAGQbuX3FtnLqaudFN8UZ/kvncrxo6FR+gmqZbNjaGhjg1tB4xG6MMT7Bi3UmTw0GxyNPMyzy+hgd49uDnR4cotqaiy6h2vBw2Do82RfeQgsAdux8ITg+OsZtyFmT3d13A7g6MP4OSp/fhRAXAPoGnRCJoGQXIhGU7EIkgpJdiERQsguRCBa3r6p8MLN+AGfKhpYBiOz3UzMUx3tRHO/lQovjYndfHhJqmuzvObDZS+fDt+oUh+JIJQ79GS9EIijZhUiExUz27Yt47LNRHO9FcbyX35s4Fu0zuxCitujPeCESYVGS3cw+bWZvmNlbZnb/YsRQjuOQme0xs1dq2VzDzB4wsxNmtvessS4ze8rM3iz/H95rauHj+IaZ9ZTPyStmdlsN4lhnZs+a2T4ze83M/rw8XtNzEomjpufEzBrN7EUze7Ucx38qj28wsx3lvPmJmdWf0wO7e03/Acig1NZqI4B6AK8C+ECt4yjHcgjAskU47o0ArgGw96yx/wrg/vLt+wH81SLF8Q0A/7bG52M1gGvKt9sAHADwgVqfk0gcNT0nKFXgtpZv5wDsAHA9gIcBfLE8/tcA/tW5PO5iXNmvA/CWu7/jpdbTDwG4YxHiWDTc/XkAA+8bvgOlxp1AjRp4kjhqjrv3uvuu8u1hlJqjXIQan5NIHDXFS1S9yetiJPtFAM7efnUxm1U6gCfN7GUz27ZIMZxhpbuf2eL0OAC+RerCc5+Z7S7/mb/gHyfOxsy6UeqfsAOLeE7eFwdQ43OyEE1eU1+g2+ru1wD4DIA/M7MbFzsgoPTOjtIb0WLwXQCXoLRHQC+Ab9bqwGbWCuAxAF919/fs5FHLcxKIo+bnxOfR5JWxGMneA+DsHkm0WeVC4+495f9PAPhbLG7nnT4zWw0A5f/5JuELiLv3lV9oMwC+hxqdEzPLoZRgP3L3n5aHa35OQnEs1jkpH3sQ59jklbEYyb4TwKbyymI9gC8CeLzWQZhZi5m1nbkN4FYAe+OzFpTHUWrcCSxiA88zyVXmTtTgnJiZodTDcL+7f+ssqabnhMVR63OyYE1ea7XC+L7VxttQWul8G8B/WKQYNqLkBLwK4LVaxgHgxyj9OTiF0meve1HaM+8ZAG8CeBpA1yLF8b8A7AGwG6VkW12DOLai9Cf6bgCvlP/dVutzEomjpucEwFUoNXHdjdIby3886zX7IoC3ADwCoOFcHlffoBMiEVJfoBMiGZTsQiSCkl2IRFCyC5EISnYhEkHJLkQiKNmFSAQluxCJ8P8BdGN5MRHQLWQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.permute(selected[0][0].cpu(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9627ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([100])\n",
      "<class 'torch.Tensor'> torch.Size([100, 3, 32, 32])\n",
      "<class 'torch.Tensor'> torch.Size([100, 64, 1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([100, 64])\n",
      "<class 'torch.Tensor'> torch.Size([100, 10])\n",
      "<class 'torch.Tensor'> torch.Size([100])\n",
      "<class 'torch.Tensor'> torch.Size([49000])\n",
      "<class 'torch.Tensor'> torch.Size([49000, 4])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 3, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([16, 3, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([10, 64])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([49000])\n",
      "<class 'torch.Tensor'> torch.Size([49000, 16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 3, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([16])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([10, 64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16, 3, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16, 3, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([10, 64])\n",
      "<class 'torch.Tensor'> torch.Size([10, 64])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.Tensor'> torch.Size([16, 3, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([16])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 16, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([32])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([10, 64])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 32, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64, 3, 3])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3051040b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResidualBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ResidualBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avg_pool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
