{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'images avec un réseau de neurones (pytorch)\n",
    "\n",
    "Dans ce notebook on se propose de classifier des images à partir d'un réseau de neurones en utilisant la bibliothèque pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail demandé :\n",
    "\n",
    "Si vous n'êtes pas familiers avec pytorch, commencez par le tutoriel de prise en main, avant d'étudier le notebook ci-dessous.\n",
    "\n",
    "Ensuite, vous devrez vous inspirer de ce tutoriel pour :\n",
    "+ 1) Implémenter un exemple de réseau simple avec une couche cachée de 128 neurones et des activations `ReLU` pour classifier les images de la base mnist. (Complétez le notebook ci-dessous)\n",
    "+ 2) Afficher l'évolution de la fonction de coût de l'ensemble de validation sur la même courbe que celle du coût sur l'ensemble d'entrainement. Y a-t-il surapprentissage ?\n",
    "+ 3) Modifier le programme pour réduire le nombre d'images d'entrainement à 1000, et entrainez à nouveau votre modèle, en analysant les résultats d'entrainement, validation et test. Qu'observez-vous ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, datasets\n",
    "%matplotlib inline\n",
    "\n",
    "#Import pytorch:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et visualisation des données\n",
    "\n",
    "On commence par charger nos données et les normaliser. Les données sont déjà séparées en une base d'entrainement et une base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de Normalisation pour passer de [0,1] vers [-1,1]]\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Dataset\n",
    "mnistTrainSet = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnistTestSet = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "X_train = mnistTrainSet.data/255\n",
    "X_test = mnistTestSet.data/255\n",
    "Y_train = mnistTrainSet.targets\n",
    "Y_test = mnistTestSet.targets\n",
    "class_names = mnistTrainSet.classes\n",
    "\n",
    "print('shape X train : ', X_train.shape)\n",
    "print('shape X test : ', X_test.shape)\n",
    "print('shape Y train : ', Y_train.shape)\n",
    "print('shape Y test : ', Y_test.shape)\n",
    "\n",
    "# Affichage de quelques images et label associé\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[Y_train[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser moins d'images on modifiera ici dans la question 3) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'exemples considérés (vous pouvez changer ici !) :\n",
    "n_train = 10000\n",
    "n_test = 10000\n",
    "\n",
    "# TODO : utiliser un Subset de n_train exemples\n",
    "# Completer pour la Question 3)\n",
    "# Pour utiliser un sous-ensemble du jeu d'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construction du modèle \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle et prédictions\n",
    "\n",
    "On définit notre réseau de neurones dans une classe spécifique ici. La fonction `forward` réalise notre propagation en avant, pour obtenir les probabilités prédites.\n",
    "\n",
    "Note : **la rétropropagation n'a pas besoin d'être implémentée, elle sera calculée automatiquement par pytorch lors de l'appel de la fonction `backward`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "# Choisir ici le nombre de neurones de la couche cachée :\n",
    "H = 10\n",
    "\n",
    "# Classe qui définit le réseau :\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # A Completer\n",
    "        )           \n",
    "    def forward(self, x):\n",
    "        # A Completer\n",
    "        return x\n",
    "    \n",
    "# Pour rendre les tirages aléatoires reproductibles (facultatif)   \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Création du réseau : \n",
    "model = Net()\n",
    "\n",
    "# Affichage de l'architecture :\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrainement\n",
    "\n",
    "### Préparation à l'entrainement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "N_epochs = 200\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix de la fonction de coût\n",
    "https://pytorch.org/docs/master/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = # A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix de l'optimiseur\n",
    "https://pytorch.org/docs/master/optim.html#algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix de l'optimiseur\n",
    "#optimizer = # A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare ici le Dataset de test en un ensemble de validation et un ensemble de test (uniquement pour la visualisation de l'évolution de la généralisation !) et on créé 3 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test Dataset\n",
    "mnistValset, mnistTestSet = random_split(mnistTestSet, \n",
    "                                                            [int(0.1 * len(mnistTestSet)), \n",
    "                                                             int(0.9 * len(mnistTestSet))])\n",
    "\n",
    "# Outil de chargement des lots de données\n",
    "mnistTrainLoader = DataLoader(mnistTrainSubset, batch_size=batch_size,shuffle=True, num_workers=0)\n",
    "mnistValLoader = DataLoader(mnistValset, batch_size=1000, shuffle=False, num_workers=0)\n",
    "mnistTestLoader = DataLoader(mnistTestSet, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la loss de validation initiale\n",
    "for features_val, labels_val in mnistValLoader: \n",
    "    labels_val_pred = model(features_val)\n",
    "    val_loss = loss_function(labels_val_pred,labels_val)  \n",
    "\n",
    "    \n",
    "print('Shape du tenseur de features de validation : ', features_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du réseau\n",
    "L'exemple ci-dessous illustre une descente de gradient simple, mais on pourra également réaliser une descente de gradient stochastique en sélectionnant des lots de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'itérations\n",
    "losses = []  \n",
    "val_losses = []\n",
    "i=0\n",
    "for epoch in range(N_epochs):  # Boucle sur les époques\n",
    "    running_loss = 0.0\n",
    "   \n",
    "    for features, labels in mnistTrainLoader:        \n",
    "        \n",
    "        #Propagation en avant\n",
    "        # A compléter\n",
    "\n",
    "        #Calcul du coût\n",
    "        # A compléter\n",
    "\n",
    "        #on sauvegarde la loss pour affichage futur\n",
    "        #losses.append(loss.item())\n",
    "\n",
    "\n",
    "        #Effacer les gradients précédents\n",
    "        # A compléter\n",
    "        \n",
    "        #Calcul des gradients (rétro-propagation)\n",
    "        # A compléter\n",
    "\n",
    "        # Mise à jour des poids : un pas de l'optimiseur\n",
    "        # A compléter\n",
    "        \n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 10 == 9:    \n",
    "        #    print('[Epoque : %d, iteration: %5d] loss: %.3f' %\n",
    "        #          (epoch + 1, i + 1, running_loss / 10))\n",
    "        #    running_loss = 0.0\n",
    "        #i+=1        \n",
    "   \n",
    "print('Entrainement terminé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher l'évolution de la fonction de coût\n",
    "fig, axes = plt.subplots(figsize=(8,6))\n",
    "axes.plot(losses,'r-',lw=2,label='Fonction de cout')\n",
    "axes.plot(val_losses,'b-',lw=2,label='Fonction de cout - validation')\n",
    "axes.set_xlabel('N iterations',fontsize=18)\n",
    "axes.set_ylabel('Cout',fontsize=18)\n",
    "plt.legend(loc='upper right',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# Pas besoin de calculer les gradient ici puisqu'on n'optimise plus\n",
    "with torch.no_grad():\n",
    "    for data in mnistTestLoader:\n",
    "        images, labels = data\n",
    "        # Propagation en avant pour calculer les prédictions\n",
    "        outputs = model(images)         \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy sur les 10000 images de test : %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(X_test.type(torch.FloatTensor))\n",
    "print('shape predictions : ', predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = F.softmax(predictions_array[i]), true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])  \n",
    "    plt.imshow(img, cmap=plt.cm.binary)  \n",
    "    predicted_label = torch.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'  \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*torch.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = F.softmax(predictions_array[i]), true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array.detach(), color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = torch.argmax(predictions_array)\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "\n",
    "\n",
    "# Affichage de quelques images et de leurs prédictions \n",
    "_, predicted = torch.max(predictions.data, 1)\n",
    "labels = Y_test\n",
    "correct = (predicted == labels)\n",
    "false = (predicted != labels)\n",
    "    \n",
    "# Affichage de quelques exemples d'erreurs\n",
    "idx_false = np.where(false)\n",
    "plt.figure(figsize=(18,12))\n",
    "K=0\n",
    "for i in idx_false[0][0:12]:  \n",
    "    plt.subplot(4,6,2*K+1)\n",
    "    plot_image(i, predictions, Y_test, X_test)\n",
    "    plt.subplot(4,6,2*K+2)\n",
    "    plot_value_array(i, predictions,  Y_test)\n",
    "    plt.xlabel(class_names[Y_test[i]])\n",
    "    K=K+1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Affichage de quelques exemples de prédictions correctes\n",
    "idx_correct = np.where(correct)\n",
    "plt.figure(figsize=(18,12))\n",
    "K=0\n",
    "for i in idx_correct[0][0:12]:  \n",
    "    plt.subplot(4,6,2*K+1)\n",
    "    plot_image(i, predictions, Y_test, X_test)\n",
    "    plt.subplot(4,6,2*K+2)\n",
    "    plot_value_array(i, predictions,  Y_test)\n",
    "    plt.xlabel(class_names[Y_test[i]])\n",
    "    K=K+1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
