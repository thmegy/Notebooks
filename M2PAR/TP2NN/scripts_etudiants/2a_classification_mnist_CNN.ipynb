{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification d'images avec un réseau de neurones convolutif (CNN)\n",
    "\n",
    "Dans ce notebook on se propose de classifier des images à partir d'un réseau de neurones en utilisant la bibliothèque pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Travail demandé :\n",
    "\n",
    "\n",
    "1. Implémentez un réseau de neurones convolutif avec l'architecture suivante : \n",
    "+ une couche de convolution avec activation ```reLU```, constituée de 32 convolutions $5\\times 5$ (stride de $1\\times1$). \n",
    "+ une couche de max pooling $2\\times2$ (stride de $2\\times2$)\n",
    "+ une couche de convolution avec activation ```reLU```, constituée de 64 convolutions $5\\times 5$ (stride de $1\\times1$).\n",
    "+ une couche de max pooling $2\\times2$  (stride de $2\\times2$).\n",
    "+ une couche complètement connectée de 1024 neurones (activation ```reLU```).\n",
    "+ la couche de sortie.\n",
    "\n",
    "Toutes les couches sont avec un padding ```SAME```, c'est-à-dire que des zéros sont ajoutés en bordure d'image pour que les masques puissent également être appliqués sur ces bords.\n",
    "\n",
    "\n",
    "2. Combien de paramètres possède ce réseau ? Justifiez en indiquant le calcul à effectuer pour trouver le résultat\n",
    "3. Quelle performance obtenez-vous ?\n",
    "4. Observez l'influence de différents paramètres sur la précision finale (nombre d'époques, taille de batch, taux d'apprentissage, etc.). Pour ces tests vous pourrez réduire le nombre d'exemples utilisés si les entrainements sont trop lents (notez que les comparaisons ne peuvent être faites que sur une même base de données et qu'il ne faudra donc pas faire varier ce nombre à chaque test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import cluster, datasets\n",
    "%matplotlib inline\n",
    "\n",
    "#Import pytorch:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et visualisation des données\n",
    "\n",
    "On commence par charger nos données et les normaliser. Les données sont déjà séparées en une base d'entrainement et une base de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de Normalisation pour passer de [0,255] vers [0,1]]\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Dataset\n",
    "mnistTrainSet = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnistTestSet = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "X_train = mnistTrainSet.data/255\n",
    "X_test = mnistTestSet.data/255\n",
    "Y_train = mnistTrainSet.targets\n",
    "Y_test = mnistTestSet.targets\n",
    "class_names = mnistTrainSet.classes\n",
    "\n",
    "print('shape X train : ', X_train.shape)\n",
    "print('shape X test : ', X_test.shape)\n",
    "print('shape Y train : ', Y_train.shape)\n",
    "print('shape Y test : ', Y_test.shape)\n",
    "\n",
    "# Affichage de quelques images et label associé\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[Y_train[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour utiliser moins d'images on complètera ici :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'exemples considérés (vous pouvez changer ici !) :\n",
    "n_train = 1000\n",
    "\n",
    "# Exemple de création d'un sous-ensemble du jeu d'entrainement\n",
    "dataset_indices= list(range(len(mnistTrainSet)))\n",
    "np.random.shuffle(dataset_indices)\n",
    "subset_indices = dataset_indices[:n_train]\n",
    "mnistTrainSubset = Subset(mnistTrainSet, subset_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Construction du modèle \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle et prédictions\n",
    "\n",
    "On définit notre réseau de neurones dans une classe spécifique ici. La fonction ```forward``` réalise notre propagation en avant, pour obtenir les probabilités prédites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe qui définit le réseau :\n",
    "class convNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNet, self).__init__()\n",
    "        # A completer\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # A completer\n",
    "        return x\n",
    "    \n",
    "# Pour rendre les tirages aléatoires reproductibles (facultatif)   \n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Création du réseau : \n",
    "model = convNet()\n",
    "\n",
    "# Affichage de l'architecture :\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrainement\n",
    "\n",
    "### Préparation à l'entrainement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "N_epochs = 30\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix de la fonction de coût\n",
    "https://pytorch.org/docs/master/nn.html#loss-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = # A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix de l'optimiseur\n",
    "https://pytorch.org/docs/master/optim.html#algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix de l'optimiseur\n",
    "#optimizer = # A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On sépare ici le Dataset de test en un ensemble de validation et un ensemble de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test Dataset\n",
    "mnistValset, mnistTestSet = random_split(mnistTestSet, \n",
    "                                                            [int(0.1 * len(mnistTestSet)), \n",
    "                                                             int(0.9 * len(mnistTestSet))])\n",
    "\n",
    "# Outil de chargement des lots de données\n",
    "mnistTrainLoader = DataLoader(mnistTrainSet, batch_size=batch_size,shuffle=True, num_workers=0)\n",
    "mnistValLoader = DataLoader(mnistValset, batch_size=1000, shuffle=False, num_workers=0)\n",
    "mnistTestLoader = DataLoader(mnistTestSet, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrainement du réseau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre d'itérations\n",
    "losses = []  \n",
    "val_losses = []\n",
    "i=0\n",
    "for epoch in range(N_epochs):  # Boucle sur les époques\n",
    "    running_loss = 0.0\n",
    "   \n",
    "    for features, labels in mnistTrainLoader:        \n",
    "        \n",
    "        #Propagation en avant\n",
    "        # A compléter\n",
    "\n",
    "        #Calcul du coût\n",
    "        # A compléter\n",
    "\n",
    "        #on sauvegarde la loss pour affichage futur\n",
    "        #losses.append(loss.item())\n",
    "\n",
    "\n",
    "        #Effacer les gradients précédents\n",
    "        # A compléter\n",
    "        \n",
    "        #Calcul des gradients (rétro-propagation)\n",
    "        # A compléter\n",
    "\n",
    "        # Mise à jour des poids : un pas de l'optimiseur\n",
    "        # A compléter\n",
    "        \n",
    "        # print statistics\n",
    "        #running_loss += loss.item()\n",
    "        #if i % 10 == 9:    \n",
    "        #    print('[Epoque : %d, iteration: %5d] loss: %.3f' %\n",
    "        #          (epoch + 1, i + 1, running_loss / 10))\n",
    "        #    running_loss = 0.0\n",
    "        #i+=1        \n",
    "   \n",
    "print('Entrainement terminé')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher l'évolution de la fonction de coût\n",
    "fig, axes = plt.subplots(figsize=(8,6))\n",
    "axes.plot(losses,'r-',lw=2,label='Fonction de cout')\n",
    "axes.plot(val_losses,'b-',lw=2,label='Fonction de cout - validation')\n",
    "axes.set_xlabel('N iterations',fontsize=18)\n",
    "axes.set_ylabel('Cout',fontsize=18)\n",
    "plt.legend(loc='upper right',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation des performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# Pas besoin de calculer les gradient ici puisqu'on n'optimise plus\n",
    "with torch.no_grad():\n",
    "    for data in mnistTestLoader:\n",
    "        images, labels = data\n",
    "        # Propagation en avant pour calculer les prédictions\n",
    "        outputs = model(images)         \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy sur les 10000 images de test : %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(X_test.type(torch.FloatTensor))\n",
    "print('shape predictions : ', predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = F.softmax(predictions_array[i]), true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])  \n",
    "    plt.imshow(img, cmap=plt.cm.binary)  \n",
    "    predicted_label = torch.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'  \n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*torch.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = F.softmax(predictions_array[i]), true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(10), predictions_array.detach(), color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = torch.argmax(predictions_array)\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')\n",
    "\n",
    "\n",
    "# Affichage de quelques images et de leurs prédictions \n",
    "_, predicted = torch.max(predictions.data, 1)\n",
    "labels = Y_test\n",
    "correct = (predicted == labels)\n",
    "false = (predicted != labels)\n",
    "    \n",
    "# Affichage de quelques exemples d'erreurs\n",
    "idx_false = np.where(false)\n",
    "plt.figure(figsize=(18,12))\n",
    "K=0\n",
    "for i in idx_false[0][0:12]:  \n",
    "    plt.subplot(4,6,2*K+1)\n",
    "    plot_image(i, predictions, Y_test, X_test)\n",
    "    plt.subplot(4,6,2*K+2)\n",
    "    plot_value_array(i, predictions,  Y_test)\n",
    "    plt.xlabel(class_names[Y_test[i]])\n",
    "    K=K+1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Affichage de quelques exemples de prédictions correctes\n",
    "idx_correct = np.where(correct)\n",
    "plt.figure(figsize=(18,12))\n",
    "K=0\n",
    "for i in idx_correct[0][0:12]:  \n",
    "    plt.subplot(4,6,2*K+1)\n",
    "    plot_image(i, predictions, Y_test, X_test)\n",
    "    plt.subplot(4,6,2*K+2)\n",
    "    plot_value_array(i, predictions,  Y_test)\n",
    "    plt.xlabel(class_names[Y_test[i]])\n",
    "    K=K+1\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
